{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmozR9UHC3w6"
   },
   "source": [
    "# Developing an ML Model End-to-End: Exercises\n",
    "\n",
    "Now that you've had some exposure to using Python for training, tuning, evaluating, and selecting an ML model, it's time to try some exercises on your own. Below, you'll find four exercises that utilize a new training data set, the Diagnostic Breast Cancer Wisconsin data set. You can read more about this data set [here](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)). When applicable, an exercise will begin with some starter code to help guide your development towards a solution to the problem. Remember, there isn't just one solution to the problem and your code may produce the similar results even if it's written differently from what is supplied in the solution notebook.\n",
    "\n",
    "These exercises are intended to be performed on Anaconda Notebooks to avoid the need to download any additional Python libraries besides `ydata_profiler`. If you decide to do these exercises on your own machine, you'll need to download the data set locally as well as any of the Python libraries used. The first code block is provided for you to download the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Python libraries needed\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import tarfile\n",
    "\n",
    "# !pip install ydata-profiling\n",
    " \n",
    "# Create a function for pulling U.S. Census data for California housing\n",
    "DOWNLOAD_ROOT = 'https://raw.githubusercontent.com/jsukup/Developing-an-ML-Model-End-to-End/master'\n",
    "DATA_PATH = os.path.join('datasets', 'cancer')\n",
    "DATA_URL = DOWNLOAD_ROOT + 'datasets/cancer/cancer.tgz'\n",
    "\n",
    "def fetch_cancer_data(data_url=DATA_URL, data_path=DATA_PATH):\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    tgz_path = os.path.join(data_path, 'cancer.tgz')\n",
    "    urllib.request.urlretrieve(data_url, tgz_path)\n",
    "    data_tgz = tarfile.open(tgz_path)\n",
    "    data_tgz.extractall(path=data_path)\n",
    "    data_tgz.close()\n",
    "\n",
    "fetch_cancer_data() # Pull data set from GitHub\n",
    "\n",
    "# Create a function for loading data into a Python object\n",
    "def load_cancer_data(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, 'cancer.csv')\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "data = load_cancer_data()\n",
    "data.head() # Inspect first five rows of data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Describe and Verify Data Quality\n",
    "\n",
    "To begin, have a look at the data set in its raw form before performing any transformations. The easiest approach is the use the `ydata_profiling` library.  Answer the following questions:\n",
    "1. Describe the data set. How many variables/features does it include? What do you believe is the target we would like to predict?\n",
    "2. Are there any missing values?\n",
    "3. Are there any highly correlated variables/features with a correlation coefficient >.7? If so, what are they? Are there any variables/features highly correlated with the target variable that might be good predictors?\n",
    "4. Are there any variables/features we can remove?\n",
    "5. What is the proportion of each label for the target variable/feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data profiler and save the output to an HTML file\n",
    "from ydata_profiling import ProfileReport \n",
    "\n",
    "profile = ProfileReport(data)\n",
    "profile.to_file('profile.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Data Preparation\n",
    "\n",
    "1. Write a function to delete any variables/features that are not useful to training the model (e.g., empty variables/features)\n",
    "2. Write a function to convert the categorical target variable/feature to a binary, numeric one.\n",
    "3. Write a function to apply `StandardScaler` to the training variables/features (but *not* the target variable/feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302          1     1.097064     -2.073335        1.269934   \n",
       "1      842517          1     1.829821     -0.353632        1.685955   \n",
       "2    84300903          1     1.579888      0.456187        1.566503   \n",
       "3    84348301          1    -0.768909      0.253732       -0.592687   \n",
       "4    84358402          1     1.750297     -1.151816        1.776573   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1     2.110995      0.721473        2.060786   \n",
       "565    926682          1     1.704854      2.085134        1.615931   \n",
       "566    926954          1     0.702284      2.045574        0.672676   \n",
       "567    927241          1     1.838341      2.336457        1.982524   \n",
       "568     92751          0    -1.808401      1.221792       -1.814389   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0     0.984375         1.568466          3.283515        2.652874   \n",
       "1     1.908708        -0.826962         -0.487072       -0.023846   \n",
       "2     1.558884         0.942210          1.052926        1.363478   \n",
       "3    -0.764464         3.283553          3.402909        1.915897   \n",
       "4     1.826229         0.280372          0.539340        1.371011   \n",
       "..         ...              ...               ...             ...   \n",
       "564   2.343856         1.041842          0.219060        1.947285   \n",
       "565   1.723842         0.102458         -0.017833        0.693043   \n",
       "566   0.577953        -0.840484         -0.038680        0.046588   \n",
       "567   1.735218         1.525767          3.272144        3.296944   \n",
       "568  -1.347789        -3.112085         -1.150752       -1.114873   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0               2.532475  ...      1.886690      -1.359293         2.303601   \n",
       "1               0.548144  ...      1.805927      -0.369203         1.535126   \n",
       "2               2.037231  ...      1.511870      -0.023974         1.347475   \n",
       "3               1.451707  ...     -0.281464       0.133984        -0.249939   \n",
       "4               1.428493  ...      1.298575      -1.466770         1.338539   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564             2.320965  ...      1.901185       0.117700         1.752563   \n",
       "565             1.263669  ...      1.536720       2.047399         1.421940   \n",
       "566             0.105777  ...      0.561361       1.374854         0.579001   \n",
       "567             2.658866  ...      1.961239       2.237926         2.303601   \n",
       "568            -1.261820  ...     -1.410893       0.764190        -1.432735   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2.001237          1.307686           2.616665         2.109526   \n",
       "1      1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2      1.456285          0.527407           1.082932         0.854974   \n",
       "3     -0.550021          3.394275           3.893397         1.989588   \n",
       "4      1.220724          0.220556          -0.313395         0.613179   \n",
       "..          ...               ...                ...              ...   \n",
       "564    2.015301          0.378365          -0.273318         0.664512   \n",
       "565    1.494959         -0.691230          -0.394820         0.236573   \n",
       "566    0.427906         -0.809587           0.350735         0.326767   \n",
       "567    1.653171          1.430427           3.904848         3.197605   \n",
       "568   -1.075813         -1.859019          -1.207552        -1.305831   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                2.296076        2.750622                 1.937015  \n",
       "1                1.087084       -0.243890                 0.281190  \n",
       "2                1.955000        1.152255                 0.201391  \n",
       "3                2.175786        6.046041                 4.935010  \n",
       "4                0.729259       -0.868353                -0.397100  \n",
       "..                    ...             ...                      ...  \n",
       "564              1.629151       -1.360158                -0.709091  \n",
       "565              0.733827       -0.531855                -0.973978  \n",
       "566              0.414069       -1.104549                -0.318409  \n",
       "567              2.289985        1.919083                 2.219635  \n",
       "568             -1.745063       -0.048138                -0.751207  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to delete any unneeded variables/features\n",
    "def delete_unnamed_32(data):\n",
    "    if 'Unnamed: 32' in data.columns:\n",
    "        return data.drop('Unnamed: 32', axis=1, inplace=True)\n",
    "    else:\n",
    "        return print(\"Variable 'Unnamed: 32' does not exist in the DataFrame.\")\n",
    "\n",
    "delete_unnamed_32(data)\n",
    "\n",
    "# Function to convert the categorical target variable/feature\n",
    "def convert_target_variable(data, target_column):\n",
    "    data[target_column] = data[target_column].map({'B': 0, 'M': 1})\n",
    "    return data\n",
    "\n",
    "convert_target_variable(data, 'diagnosis')\n",
    "\n",
    "# Function to apply `StandardScaler`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_standard_scaler(data):\n",
    "    scaler = StandardScaler()\n",
    "    data.iloc[:,2:] = scaler.fit_transform(data.iloc[:,2:])\n",
    "    return data\n",
    "\n",
    "apply_standard_scaler(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Model Development\n",
    "\n",
    "1. Split the data set into training data and testing data using the `scikit-learn` function `train_test_split`. You should create 4 new Python objects: `x_train`,`x_test`,`y_train`,`y_test`. This way we'll hold the target variable/feature in it's own object. Use an 80/20 train/test split with the `random_state=734`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "y = data['diagnosis']\n",
    "x = data.drop(['id','diagnosis'], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=734) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train up to 3 different models using `scikit-learn` to build a model that predicts the target variable/feature using the training variables/features. Since the target is a discrete value, this will be a classification model. More information on models and `scikit-learn` can be found [here](https://scikit-learn.org/stable/). After training, save each model's prediction on the testing data in a new Python object. You don't have to adjust the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(x_train, y_train)\n",
    "\n",
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "# K-Nearest Neighbors model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate each model using a simple measurement of Accuracy (use the `scikit-learn` method `.score()`) comparing the predicted values with the actual values in the `y_test` Python object created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:\n",
      " Logistic regression: 0.9912280701754386,\n",
      " Random Forest: 0.9824561403508771,\n",
      " SGD: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "# Model accuracy\n",
    "lr_score = lr_clf.score(x_test, y_test)\n",
    "rf_score = rf_clf.score(x_test, y_test)\n",
    "sgd_score = sgd_clf.score(x_test, y_test)\n",
    "\n",
    "print(f\"Model accuracy:\\n Logistic regression: {lr_score},\\n Random Forest: {rf_score},\\n SGD: {sgd_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Hyperparameter Optimization and Model Selection\n",
    "\n",
    "Now that we've trained a few candidate models, we can try and improve their performance using hyperparameter optimization.\n",
    "\n",
    "1. Chose a single model or all the candidate models to perform hyperparameter optimization on. You may use the built-in tools in `scikit-learn` that we used in the course exercises (e.g., `GridSearchCV` and `RandomizedSearchCV`). Remember to choose a `scoring` parameter that's suitable for a classification model like `accuracy`! You should be able to reuse a lot of the same code from the course lab, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal estimated hyperparameters: RandomForestClassifier(max_features=8, n_estimators=10, random_state=734)\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model using grid search with cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a list of hyperparameter values set as key:value pairs\n",
    "param_grid = [\n",
    "    # Try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 5, 10, 30], 'max_features': [2, 4, 6, 8, 10]},\n",
    "    # Try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "# Train Random Forest model\n",
    "forest_clf = RandomForestClassifier(random_state=734)\n",
    "\n",
    "# Five fold cross-validation: (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_clf, \n",
    "                           param_grid, \n",
    "                           cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           return_train_score=True)\n",
    "\n",
    "# Fit model to training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print best parameters and estimator\n",
    "print(f\"Optimal estimated hyperparameters: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Optimal estimated hyperparameters: RandomForestClassifier(max_features=5, n_estimators=168, random_state=734)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest model using grid search with cross-validation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Create a range of hyperparameter values set as key:value pairs\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "}\n",
    "\n",
    "# Train Random Forest model\n",
    "forest_clf = RandomForestClassifier(random_state=734)\n",
    "\n",
    "# Five fold cross-validation: (12+6)*5=90 rounds of training \n",
    "rand_search = RandomizedSearchCV(forest_clf, \n",
    "                                 param_distribs,\n",
    "                                 cv=5,\n",
    "                                 scoring='accuracy',\n",
    "                                 return_train_score=True)\n",
    "\n",
    "# Fit model to training data\n",
    "rand_search.fit(x_train, y_train)\n",
    "\n",
    "# Print best parameters and estimator\n",
    "print(f\"Optimal estimated hyperparameters: {rand_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare the results of the first model(s) to the second model(s) with optimal hyperparameters. You'll probably have different results depending on which technique was used. Which model performs the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:\n",
      " Random Forest (GS): 0.9824561403508771,\n",
      " Random Forest (RS): 0.9736842105263158,\n",
      " Random Forest (default): 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model with GridSearch optimal hyperparameters\n",
    "forest_gs = RandomForestClassifier(max_features=8, n_estimators=10, random_state=734)\n",
    "forest_gs.fit(x_train, y_train)\n",
    "forest_gs_score = forest_gs.score(x_test, y_test)\n",
    "\n",
    "# Train a Random Forest model with the RandomSearch optimal hyperparameters\n",
    "forest_rs = RandomForestClassifier(max_features=5, n_estimators=168, random_state=734)\n",
    "forest_rs.fit(x_train, y_train)\n",
    "forest_rs_score = forest_rs.score(x_test, y_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model accuracy:\\n Random Forest (GS): {forest_gs_score},\\n Random Forest (RS): {forest_rs_score},\\n Random Forest (default): {rf_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats! That's the end of the exercises!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "The Machine Learning Pipeline.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
