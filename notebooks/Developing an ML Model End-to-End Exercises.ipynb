{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmozR9UHC3w6"
   },
   "source": [
    "# Developing an ML Model End-to-End: Exercises\n",
    "\n",
    "Now that you've had some exposure to using Python for training, tuning, evaluating, and selecting an ML model, it's time to try some exercises on your own. Below, you'll find four exercises that utilize a new training data set, the Diagnostic Breast Cancer Wisconsin data set. You can read more about this data set [here](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)). When applicable, an exercise will begin with some starter code to help guide your development towards a solution to the problem. Remember, there isn't just one solution to the problem and your code may produce the similar results even if it's written differently from what is supplied in the solution notebook.\n",
    "\n",
    "These exercises are intended to be performed on Anaconda Notebooks to avoid the need to download any additional Python libraries besides `ydata_profiler`. If you decide to do these exercises on your own machine, you'll need to download the data set locally as well as any of the Python libraries used. The first code block is provided for you to download the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries needed\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import tarfile\n",
    "\n",
    "# !pip install ydata-profiling\n",
    "\n",
    "# Create a function for pulling U.S. Census data for California housing\n",
    "DOWNLOAD_ROOT = (\n",
    "    \"https://raw.githubusercontent.com/jsukup/Developing-an-ML-Model-End-to-End/master/\"\n",
    ")\n",
    "DATA_PATH = os.path.join(\"datasets\", \"cancer\")\n",
    "DATA_URL = DOWNLOAD_ROOT + \"datasets/cancer/cancer.tgz\"\n",
    "\n",
    "\n",
    "def fetch_cancer_data(data_url=DATA_URL, data_path=DATA_PATH):\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    tgz_path = os.path.join(data_path, \"cancer.tgz\")\n",
    "    urllib.request.urlretrieve(data_url, tgz_path)\n",
    "    data_tgz = tarfile.open(tgz_path)\n",
    "    data_tgz.extractall(path=data_path)\n",
    "    data_tgz.close()\n",
    "\n",
    "\n",
    "fetch_cancer_data()  # Pull data set from GitHub\n",
    "\n",
    "\n",
    "# Create a function for loading data into a Python object\n",
    "def load_cancer_data(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, \"cancer.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "data = load_cancer_data()\n",
    "data.head()  # Inspect first five rows of data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Describe and Verify Data Quality\n",
    "\n",
    "To begin, have a look at the data set in its raw form before performing any transformations. The easiest approach is the use the `ydata_profiling` library.  Answer the following questions:\n",
    "1. Describe the data set. How many variables/features does it include? What do you believe is the target we would like to predict?\n",
    "2. Are there any missing values?\n",
    "3. Are there any highly correlated variables/features with a correlation coefficient >.7? If so, what are they? Are there any variables/features highly correlated with the target variable that might be good predictors?\n",
    "4. Are there any variables/features we can remove?\n",
    "5. What is the proportion of each label for the target variable/feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Data Preparation\n",
    "\n",
    "1. Write a function to delete any variables/features that are not useful to training the model (e.g., empty variables/features)\n",
    "2. Write a function to convert the categorical target variable/feature to a binary, numeric one.\n",
    "3. Write a function to apply `StandardScaler` to the training variables/features (but *not* the target variable/feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete any unneeded variables/features\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Function to convert the categorical target variable/feature\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Function to apply `StandardScaler`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Model Development\n",
    "\n",
    "1. Split the data set into training data and testing data using the `scikit-learn` function `train_test_split`. You should create 4 new Python objects: `x_train`,`x_test`,`y_train`,`y_test`. This way we'll hold the target variable/feature in it's own object. Use an 80/20 train/test split with the `random_state=734`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train up to 3 different models using `scikit-learn` to build a model that predicts the target variable/feature using the training variables/features. Since the target is a discrete value, this will be a classification model. More information on models and `scikit-learn` can be found [here](https://scikit-learn.org/stable/). After training, save each model's prediction on the testing data in a new Python object. You don't have to adjust the default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate each model using a simple measurement of Accuracy (use the `scikit-learn` method `.score()`) comparing the predicted values with the actual values in the `y_test` Python object created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuracy\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Hyperparameter Optimization and Model Selection\n",
    "\n",
    "Now that we've trained a few candidate models, we can try and improve their performance using hyperparameter optimization.\n",
    "\n",
    "1. Chose a single model or all the candidate models to perform hyperparameter optimization on. You may use the built-in tools in `scikit-learn` that we used in the course exercises (e.g., `GridSearchCV` and `RandomizedSearchCV`). Remember to choose a `scoring` parameter that's suitable for a classification model like `accuracy`! You should be able to reuse a lot of the same code from the course lab, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model using grid search with cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a list of hyperparameter values set as key:value pairs\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model using grid search with cross-validation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Create a range of hyperparameter values set as key:value pairs\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare the results of the first model(s) to the second model(s) with optimal hyperparameters. You'll probably have different results depending on which technique was used. Which model performs the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats! That's the end of the exercises!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "The Machine Learning Pipeline.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
